---
title: "Day 1 - A few notes on the probability theory"
subtitle: "Flip a coin and compute the likelihood"
author: Kevin Cazelles
institute: University of Guelph
date: August 14, 2017
documentclass: eecslides
babel-lang: english
output:
  beamer_presentation:
    highlight: tango
    includes:
      in_header: header.tex
# Rscript -e 'rmarkdown::render("Day1.Rmd", "all")'
# (am: 1h20 + 1h20 / pm 2h + 15min)
---



\huge{PART 1}

\LARGE

Probability theory from scratch


# History


```{r setup, echo = FALSE}
library(graphicsutils)
myblue <- "#7eb6d6"
myred <- "#e080a3"
mygreen <- "#d4e09b"
mygrey <- "grey35"
mypar <- list(fg=mygrey, col.lab=mygrey, col.axis=mygrey, bg="transparent", las = 1, cex.main=2, cex.axis=1.4, cex.lab=1.4, bty="l")
```



# A few short and biased notes on History

- Chevalier De Méré, Pascal and Fermat: *the problem of points*
  - prediction based on data / envision outcomes

# Few notes about History

- Laplace *Théorie Analytique des Probabilités in 1812* and

- Reverend Bayes *An Essay Towards Solving a Problem in the Doctrine of Chances* 	(published posthumously)


# Few notes about History

- Kolmogorov / Mathematization

- Shannon / Tukey / Update information theory


# Examples

- Heisenberg / Einstein  

\pause

- A population as a distribution of traits (population genetics)

\pause

- Allesina and Tang, **Stability criteria for complex ecosystems.**, *Nature* (2012),
based on Tao, Vu & Krishnapur, **Random matrices: Universality of ESDs and the circular law.**, *The Annals of Probability* (2010).

\pause

- Short talk this pm!




# Probability space (1/3)

\pause

\begin{large}
$\left(\Omega, \mathcal{F}, P\right)$
\end{large}


\pause

1. $\Omega$: Sample space set of all possible outcomes  

\begin{itemize}
     \item<4-6> "Head" "Tail"
 \end{itemize}  

\pause

2. $\mathcal{F}$: set of events *i.e.* 0 or more outcomes

\begin{itemize}
     \item<5-6> $\emptyset$, "Head", "Tail", "Head or Tail" ($\Omega$)
 \end{itemize}   

\pause

3. $P$: assign a probability / map events occurrence into [0,1]

\begin{itemize}
     \item<6-6> \alert<6>{$P(\emptyset)=0$};  $P("Head") = p$;  $P("Tail") = 1-p$; \alert<6>{$P(\Omega) = 1$}
 \end{itemize}  



# Probability space (2/3)

\begin{large}
Occurrence of species 1 on an island
\end{large}


1. $\Omega$: Sample space set of all possible outcomes  

\begin{itemize}
     \item<4-6>  {"Present", "Absence"} ({"0", "1"})
 \end{itemize}  

\pause

2. $\mathcal{F}$: set of events *i.e.* 0 or more outcomes

\begin{itemize}
     \item<5-6> $\emptyset$, "0", "1", "1 or 0" ($\Omega$)
 \end{itemize}   

\pause

3. $P$: assign a probability / map events occurrence into [0,1]

\begin{itemize}
     \item<6-6> \alert<6>{$P(\emptyset)=0$};  $P("1") = p$;  $P("0") = 1-p$; \alert<6>{$P(\Omega) = 1$}
 \end{itemize}  

 <!-- Understanding the difference between Omega and F is ++ -->
 <!-- The set of question F allows is huge and we need to combine outcomes properly -->



# Probability space (3/3)

\begin{large}
  Occurrence of species 1 and species 2 on an island
\end{large}

   1. $\Omega$

   \begin{itemize}
        \item<2-4> {"00", "01", "10", "11"}
    \end{itemize}  

   2. $\mathcal{F}$

   \begin{itemize}
        \item<3-4> $\emptyset$, $\Omega$, "01", "at least one species"
    \end{itemize}   

   3. $P$: assigns probabilities to events


<!-- On a envie de dire qu'on multiplie les proba... mais il faut penser que... Question how to combine events -->



# Combining events

- Let's "A" and "B" denotes two distinct events:

    - $\overline{A}$: "complement of A"
    \pause
    - $A \bigcup B$: "A or B"
    \pause
    - $A \bigcap B$: "A and B"


# Combining events

```{r omega, echo = FALSE, fig.width=6, fig.height=4.5}
par(xaxs="i", yaxs="i")
plot0(c(0,1), fill=myblue)
text(.9,.1, label=expression(Omega), cex=2.6, col=mygrey)
box2(1:4, col=mygrey)
```

\LARGE $P(\Omega) = 1$


# Combining events

```{r emptySet, echo = FALSE, fig.width=6, fig.height=4.5}
##---
par(xaxs="i", yaxs="i")
plot0(c(0,1))
text(.9,.1, label=expression(bar(Omega)), cex=2.6, col=mygrey)
box2(1:4, col=mygrey)
```

\LARGE $P(\overline{\Omega}) = P(\emptyset) = 1 - P(\Omega) = 0$



# Combining events

```{r eventA, echo = FALSE, fig.width=6, fig.height=4.5}
rc1 <- c(.2,.4,.6,.8)
rc2 <-  c(.4,.2,.8,.6)
##---
par(xaxs="i", yaxs="i")
plot0(c(0,1))
rect(rc1[1], rc1[2], rc1[3], rc1[4], col = myblue, border=NA)
text(mean(rc1[c(1,3)]), mean(rc1[c(2,4)]), label="A", cex=2.6, col=mygrey)
box2(1:4, col=mygrey)
```

\LARGE $P(A)$


# Combining events

```{r complement, echo = FALSE, fig.width=6, fig.height=4.5}
par(xaxs="i", yaxs="i")
plot0(c(0,1), fill=myblue)
rect(rc1[1], rc1[2], rc1[3], rc1[4], col = "white", border=NA)
box2(1:4, col=mygrey)
text(.9,.1, label=expression(bar(A)), cex=2.6, col=mygrey)
```

\LARGE $P(\overline{A}) = 1 - P(A)$


# Combining events


```{r eventB, echo = FALSE, fig.width=6, fig.height=4.5}
par(xaxs="i", yaxs="i")
plot0(c(0,1))
rect(rc2[1], rc2[2], rc2[3], rc2[4], col = myblue, border=NA)
text(mean(rc2[c(1,3)]), mean(rc2[c(2,4)]), label="B", cex=2.6, col=mygrey)
box2(1:4, col=mygrey)
```

\LARGE $P(B)$


# Combining events

```{r interAB, echo = FALSE}
par(xaxs="i", yaxs="i")
plot0(c(0,1))
rect(rc1[1], rc1[2], rc1[3], rc1[4], col = NA, border=mygrey, lwd=.4)
rect(rc2[1], rc2[2], rc2[3], rc2[4], col = NA, border=mygrey, lwd=.4)
rect(rc2[1], rc1[2], rc1[3], rc2[4], col = myblue, border=NA)
text(.5*(rc2[1]+rc1[3]) , .5*(rc1[2]+rc2[4]), label= expression(A~intersect(B)), cex=2.6, col=mygrey)
box2(1:4, col=mygrey)
```

\LARGE $P(A \bigcap B)$


<!-- we assume this is known we'll come back latter on that -->


# Combining events


```{r eventAB, echo = FALSE, fig.width=6, fig.height=4.5}
par(xaxs="i", yaxs="i")
plot0(c(0,1))
rect(rc1[1], rc1[2], rc1[3], rc1[4], col = myblue, border=NA)
rect(rc2[1], rc2[2], rc2[3], rc2[4], col = myblue, border=NA)
text(mean(rc2[c(1,3)])-.1, mean(rc2[c(2,4)])+.1, label= expression(A~union(B)), cex=2.6, col=mygrey)
box2(1:4, col=mygrey)
```

\LARGE $P(A \bigcup B) = P(A) + P(B) - P(A \bigcap B)$


# Combining events

```{r complementAB, echo = FALSE}
par(xaxs="i", yaxs="i")
plot0(c(0,1), fill=myblue)
rect(rc1[1], rc1[2], rc1[3], rc1[4], col = "white", border=NA)
rect(rc2[1], rc2[2], rc2[3], rc2[4], col = "white", border=NA)
text(.85, .1, label= expression(bar(A~union(B))), cex=2.6, col=mygrey)
box2(1:4, col=mygrey)
```

\LARGE $P(\overline{A \bigcup B}) = 1 - P(A \bigcup B)$




# Combining events - disjoint events

```{r disjoint, echo = FALSE}
par(xaxs="i", yaxs="i")
plot0(c(0,1), fill=myblue)
rect(rc1[1]-.1, rc1[2], rc1[3]-.1, rc1[4], col = "white", border=mygrey)
rect(rc2[1]+.1, rc2[2], rc2[3]+.1, rc2[4], col = "white", border=mygrey)
text(.85, .1, label= expression(bar(A~union(B))), cex=2.6, col=mygrey)
box2(1:4, col=mygrey)
```

\LARGE $P(\overline{A \bigcap B}) = 0$




# Combining events - partition

\large

Consider an event B and a set of events: $A_i$ where i $\in$ \{1,...,n\} ($n$ a natural number) such as:

\pause

1. $\forall$ \{i, j\} \\ $i \neq j$, $P(A_i \bigcap A_j) = 0$  (pairwise disjoint)

\pause

2. $\bigcap_i^n A_i = B$ $\Rightarrow$ $\sum_i^n P(A_i) = P(B)$


then, the set $A_i$ is a partition of B.


# Combining events - partition

```{r partition, echo = FALSE, fig.width=6, fig.height=4.5}
layout(matrix(c(1,1,2,3,4,4,3,5,5),3,3))
par(xaxs="i", yaxs="i", mar=c(0,0,0,0))
for (i in 1:5){
  plot0(c(-1,1), c(-1,1), fill=darken(myblue, 12*(i-1)+1))
  text(0,0, paste0("A",i), cex=2.8, col="white")
}
```

# Combining events - partition

\large

$A_i$ where $i \in \{1, 2, 3, 4, 5\}$ is a partition of $\Omega$

$$\sum_i^5 P(A_i) = 1$$



# Occurrence of species 1 and species 2 on an island

\large

- Events: \{"00", "01", "10", "11"\}

\pause

- $P("00" \bigcap "01") = 0$

\pause

- $"00" \bigcup "01" \bigcup "10" \bigcup "11" = \Omega$

\pause

- $p_{00}$ + $p_{01}$ + $p_{10}$ + $p_{11}$ = 1


# Occurrence of species 1 and species 2 on an island



- "00", "01", "10", "11" are **singleton sets** (a.k.a unit sets).

\pause

- \{"00", "01", "10", "11"\} a partition of singleton sets.

\pause

-  $p_{00}$, $p_{01}$, $p_{10}$, $p_{11}$

\pause

Describes a **probability distribution**.




# Let's practice 1 (15 min)

\begin{exampleblock}{PRACTICE 1}
  \begin{itemize}
      \item<1-5> $P(\overline{A} \bigcap B) = f(P(A), P(B), P(A \bigcap  B))$
      \item<2-5> $P(A \bigcup B \bigcup C)$
      \item<3-5> the duck hunter 1 bullet
      \item<4-5> the duck hunter 2 bullets / 2 ducks - 1 duck
      \item<5-5> bonus: how to simulate a dice using a coin?
  \end{itemize}    
\end{exampleblock}



# Let's practice 1 - $P(\overline{A \bigcup B})$

```{r interAcomplB, echo = FALSE}
par(xaxs="i", yaxs="i")
plot0(c(0,1))
rect(rc2[1], rc2[2], rc2[3], rc2[4], col = myblue, border=NA, lwd=.4)
rect(rc1[1], rc1[2], rc1[3], rc1[4], col = "white", border = mygrey, lwd=.4)
rect(rc2[1], rc2[2], rc2[3], rc2[4], col = NA, border=mygrey, lwd=.4)

text(.5*(rc2[1]+rc2[3]), .5*(rc2[2]+rc2[4])-.1, label= expression(bar(A)~intersect(B)), cex=2.6, col=mygrey)
box2(1:4, col=mygrey)
```

\LARGE $P(\overline{A \bigcup B}) = ?$


# Let's practice 1 - $P(A \bigcup B \bigcup C)$

```{r eventABC, echo = FALSE}
par(xaxs="i", yaxs="i")
plot0(c(0,1))
##--
rect(rc2[1]+.1, rc2[2]+.1, rc2[3]+.1, rc2[4]+.1, col = myblue, border = NA, lwd=.4)
rect(rc1[1]+.1, rc1[2]+.1, rc1[3]+.1, rc1[4]+.1, col = myblue, border = NA, lwd=.4)
rect(rc2[1]-.15, rc2[2]-.05, rc2[3]-.15, rc2[4]-.05, col = myblue, border = NA, lwd=.4)
##--
rect(rc2[1]+.1, rc2[2]+.1, rc2[3]+.1, rc2[4]+.1, col = NA, border = mygrey, lwd=.4)
rect(rc1[1]+.1, rc1[2]+.1, rc1[3]+.1, rc1[4]+.1, col = NA, border = mygrey, lwd=.4)
rect(rc2[1]-.15, rc2[2]-.05, rc2[3]-.15, rc2[4]-.05, col = NA, border = mygrey, lwd=.4)
##--
text(c(.35,.8,.3), c(.8,.5,.2), labels=LETTERS[1:3], col=mygrey, cex=2)
box2(1:4, col=mygrey)
```

\LARGE $P(A \bigcup B \bigcup C) = ?$


# Let's practice 1 - the duck hunter

![Daffy & Elmer](Image/duckHunter.png){width=60%}

\vspace{-.5cm}

- Duck hunter with one bullet, one duck: describe what happens.

- Duck hunter with two bullets, two ducks: describe what happens.

- Duck hunter with two bullets, one duck: describe what happens.


# Solution 1


<!-- # Solution 1 - $P(\overline{A \bigcup B})$


# Solution 1 - $P(A \bigcup B \bigcup C)$

 - See the [Inclusion–exclusion principle](https://en.wikipedia.org/wiki/Inclusion–exclusion_principle) article on wikipedia (formule du crible de Poincaré).


# Solution 1 - the duck hunter -->






# Random variables

- Flipping a coin / occurrence of 1 species on an island / shooting a duck $\rightarrow$ we applied similar probabilistic approach.  

\pause

- *Success*: "Head", "Presence", "one dead duck" $\rightarrow$ **1**

\pause

- *Failure*: "Tails", "Absence", "no dinner tonight" $\rightarrow$ **0**

\pause

- Now let $X$ denote a variable such as:
  - $X=1$ success: $P(X) = p$ ;
  - $X=1$ failure:  $P(\overline{X}) = 1- p$

\pause

- Define a random variable + assign a probability distribution.


# Random variables and probability distribution

Formally:

- A **random variable** $X: \Omega \rightarrow M$ where M is a measurable
space (natural number, real number, ...)

\pause

- A **probability distribution** $f$ is a function that assigns probability
under certain constraints:

\pause

  - $f$ specifies $P$ for the partition of $\Omega$ made of singletons  
  \pause

\pause

  - $f$ defines $p_{00}$, $p_{01}$, $p_{10}$, $p_{11}$ such as $\sum p_i = 1$

<!-- choices we made -->




# Independence - Intuition

```{r tree1, echo = FALSE, fig.width=7, fig.height=4.5}
par(xaxs="i", yaxs="i")
plot0(c(0,1), c(0,1.1))
arrows(.15, .5, .4, .75, col=mygrey, lwd = 2)
arrows(.15, .5, .4, .25, col=mygrey, lwd = 2)
## --
text(c(.4), c(.75), labels = expression(X), pos = 4, cex=2, col=mygrey)
text(c(.4), c(.25), labels = expression(bar(X)), pos = 4, cex=2, col=mygrey)
## --
text(c(.25), c(.68), labels = "p", cex=1.4, col=myblue)
text(c(.25), c(.32), labels = "1-p", cex=1.4, col=myblue)
## --
text(.25, 1.04, "SHOOT 1", col=mygreen)
```


# Independence - Intuition

```{r tree2, echo = FALSE, fig.width=7, fig.height=4.5}
par(xaxs="i", yaxs="i")
plot0(c(0,1), c(0,1.1))
arrows(.15, .5, .4, .75, col=mygrey, lwd = 2)
arrows(.15, .5, .4, .25, col=mygrey, lwd = 2)
## --
text(c(.4, .7, .7), c(.75, .9, .4), labels = expression(X), pos = 4, cex=2, col=mygrey)
text(c(.4, .7, .7), c(.25, .6, .1), labels = expression(bar(X)), pos = 4, cex=2, col=mygrey)
## --
text(c(.25, .55, .55), c(.68, .88, .42), labels = "p", cex=1.4, col=myblue)
text(c(.25, .55, .55), c(.32, .1, .6), labels = "1-p", cex=1.4, col=myblue)
## --
text(.25, 1.04, "SHOOT 1", col=mygreen)
text(.55, 1.04, "SHOOT 2", col=mygreen)
## --
y2 <- c(.9, .6, .4, .1)
for (i in y2) arrows(.47, .25+(i>.5)*.5, .7, i, col=mygrey, lwd = 2)
## --
```


# Independence - Intuition

```{r tree2b, echo = FALSE, fig.width=7, fig.height=4.5}
par(xaxs="i", yaxs="i")
plot0(c(0,1), c(0,1.1))
arrows(.15, .5, .4, .75, col=mygrey, lwd = 2)
arrows(.15, .5, .4, .25, col=mygrey, lwd = 2)
## --
text(c(.4, .7, .7), c(.75, .9, .4), labels = expression(X), pos = 4, cex=2, col=mygrey)
text(c(.4, .7, .7), c(.25, .6, .1), labels = expression(bar(X)), pos = 4, cex=2, col=mygrey)
## --
text(c(.25, .55, .55), c(.68, .88, .42), labels = "p", cex=1.4, col=myblue)
text(c(.25, .55, .55), c(.32, .1, .6), labels = "1-p", cex=1.4, col=myblue)
## --
text(.25, 1.04, "SHOOT 1", col=mygreen)
text(.55, 1.04, "SHOOT 2", col=mygreen)
## --
text(rep(.78, 4), c(.9,.6,.4,.1), labels = c("pp", "p(1-p)", "(1-p)p", "(1-p)(1-p)"), cex=1.4, col=myblue, pos=4)
y2 <- c(.9, .6, .4, .1)
for (i in y2) arrows(.47, .25+(i>.5)*.5, .7, i, col=mygrey, lwd = 2)
## --
```

# Independence - Intuition

```{r tree3, echo = FALSE, fig.width=7, fig.height=4.5}
par(xaxs="i", yaxs="i")
plot0(c(0,1), c(0,1.1))
arrows(.15, .5, .4, .75, col=mygrey, lwd = 2)
arrows(.15, .5, .4, .25, col=mygrey, lwd = 2)
## --
text(c(.4, .7, .7), c(.75, .9, .4), labels = expression(X), pos = 4, cex=2, col=mygrey)
text(c(.4, .7, .7), c(.25, .6, .1), labels = expression(bar(X)), pos = 4, cex=2, col=mygrey)
## --
text(c(.25), c(.68), labels = "p", cex=1.4, col=myblue)
text(c(.25), c(.32), labels = "1-p", cex=1.4, col=myblue)
## --
text(.25, 1.04, "SHOOT 1", col=mygreen)
text(.55, 1.04, "SHOOT 2", col=mygreen)
## --
# text(rep(.78, 4), c(.9,.6,.4,.1), labels = "?", cex=1.4, col=myblue, pos=4)
y2 <- c(.9, .6, .4, .1)
for (i in y2) arrows(.47, .25+(i>.5)*.5, .7, i, col=mygrey, lwd = 2)
## --
```

# Independence - Intuition

```{r tree3b, echo = FALSE, fig.width=7, fig.height=4.5}
par(xaxs="i", yaxs="i")
plot0(c(0,1), c(0,1.1))
arrows(.15, .5, .4, .75, col=mygrey, lwd = 2)
arrows(.15, .5, .4, .25, col=mygrey, lwd = 2)
## --
text(c(.4, .7, .7), c(.75, .9, .4), labels = expression(X), pos = 4, cex=2, col=mygrey)
text(c(.4, .7, .7), c(.25, .6, .1), labels = expression(bar(X)), pos = 4, cex=2, col=mygrey)
## --
text(c(.25, .55, .55), c(.68, .88, .42), labels = c("p", 0, 0), cex=1.4, col=myblue)
text(c(.25, .55, .55), c(.32, .1, .6), labels = c("1-p", 1, 1), cex=1.4, col=myblue)
## --
text(.25, 1.04, "SHOOT 1", col=mygreen)
text(.55, 1.04, "SHOOT 2", col=mygreen)
## --
text(rep(.78, 4), c(.9,.6,.4,.1), labels = "?", cex=1.4, col=myblue, pos=4)
y2 <- c(.9, .6, .4, .1)
for (i in y2) arrows(.47, .25+(i>.5)*.5, .7, i, col=mygrey, lwd = 2)
## --
```

<!-- it depends on what happens before -->



# Independence - Definition

\large

To events are independent if and only if:

- $P(A \cap B) = P(A)P(B)$

\pause
Remarks:

  1. this is an assumption often implicit (notably in statistics)  

  \pause

  2. events that may not seem independent in the common sens may be independent
  independent    

  \pause

  3. $P(A \bigcup B) = P(A) + P(B) - P(A)P(B)$


# Let's practice 2 (10 min)

The duck hunter as success rate of $p$ and he is gonna shoot $n$ independent ducks!

\pause

  1. what's the probability he failed the $n-1$ first shoots and succeed the last one   

  \pause

  2. what's the probability he shooted exactly $p$ ducks (starts with n=3).


# Solution 2



# Finite and countably infinite sets


1. Finite set: X = \{ 1, 2, ..., n \}

\pause

  - binomial distribution

  - hypergeometric distribution


\pause

2. Countably infinite set X =  \{ 1, 2, 3, ..., +$\infty$ \}

\pause

  - negative binomial   

  - poisson

\pause

\vspace{-.5cm}

\LARGE

$$\sum_i^{+ \infty} P(X_i)$$


# Finite set - binomial


# Countably infinite - negative binomial


# Countably infinite - negative binomial


<!-- dire quel function est la probab de dictroution -->


# Infinite set

# Infinite set


- Time upon arrival

- presence of a species on a give point

- all events have a probabililty of 0.
- in half of the area we wanna say .5...

# Infinite set

    3. distributions pdf/cdf (ex: pdf next slides)


# Probability distribution - act 2

  - Probability mass, Probability mass function, p.m.f., Discrete probability distribution function

  - Probability mass, Probability mass function, p.m.f., Discrete probability distribution function

  - Cumulated $P(X \leq x)$



# Example time upon at a party
  <!--I used random names David / William / Amaël -->


# Infinite set

<!-- probability distribution function -->
<!-- a probability mass function -->
<!-- add also discrete proba example -->

```{r distrib, echo=FALSE}
seqx <- seq(-7,7,0.1)
par(mypar)
plot(seqx, dnorm(seqx), type="l", col=myblue, lwd=4, main = "dnorm")
```



<!-- Cumulative distribution function -->


# Other distribution (exponential / lognormal)

 - Constraints on the function f
 - regularity properties, continuous except on a countable number of point exponentiel is not continuous in 0.



# PAUSE

PAUSE \large{PAUSE} \Large{PAUSE} \LARGE{PAUSE} \huge{PAUSE} \Huge{PAUSE}
















----

\huge{PART 2}

\LARGE

Moments

The Bayes theorem


# Expectation / Variance

\large

Notations: $X$, $x$

$$E(X) = \int xf(x)dx$$

\pause

$$V(X) = \int (x-E(x))^2f(x)dx$$



# Moments

\large

$$E(X^n) = \int x^nf(x)dx$$

Moment-generating function (MGF) alternative speciation of the distribution.



# Quantile

\large

$$\alpha ~ | ~ P(X \leq x) = \alpha$$


- media   
- 1st third quartile  
- 5 / 95 percentile   


# Quantile

```{r boxplot, echo=FALSE, fig.width=7, fig.height=5.5}
val <- rnorm(1001)
par(mypar)
par(xaxs="i", yaxs="i")
plot0(c(0.6, 1.8), c(-4,4))
boxplot(val, add=T, outline=F)
abline(h=quantile(val, c(.25,.5,.75)), lty=2, lwd=c(1,1.5,1), col = c(mygreen, 1, mygreen))
text(1.4, quantile(val, .25)-0.25, labels = c("1st quartile"), pos=4, col = mygreen)
text(1.4, quantile(val, .75)+0.25, labels = c("3rd quartile"), pos=4, col = mygreen)
```


# Example Expectation / Variance


# Let's practice 3

\begin{exampleblock}{Practice 4}
    - $p$ success a bullet is 3$ (including the )
    - A duck of the same quality is 60$
    - for which value of $p$ the duck hunter should better stay home?
\end{exampleblock}



# Independence act 2

- Go back to the hunter and duck paradigm (tree for the same duck)


# Independence act 2

Let's A and B be two events:

$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$

$$P(A \bigcap B) = P(A|B)P(B)$$

Independence :

$$P(A|B) = P(A)$$

$$P(A|\overline{B}) = P(A)$$

$$P(A \cap B) = P(A|B)P(B)$$


# Bayes theorem


$$P(A \cap B) = P(B \cap A)$$

\pause

$$P(A|B)P(B) = P(B|A)P(A)$$

\pause

\LARGE

$$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$


# Bayes theorem

- What the reverend said: the original question he asked!

$$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$

- Implications: cause/consequence swap


# Bayes theorem

Set of $C_i$ is a partition of B.

$$P(A|B) = \frac{P(B|A)P(A)}{\sum P(C_i)}$$




# Practice 4 (40 min - 3 slides)



\begin{exampleblock}{Practice 4}
\begin{itemize}
    \item<1-2> classical examples (20 min)
    \item<2-2> the duck hunter is back (20 min)
\end{itemize}    
\end{exampleblock}



# LUNCH

\large{LUNCH} \Large{LUNCH} \LARGE{LUNCH} \huge{LUNCH} \Huge{LUNCH}





















# Part 3

\Large{Probability theory and statistics }


# Let's go back to the last practice


# Probability theory and statistics  

- Information theory
- Using data to predict
- Frequentists way / Bayesian way
- Estimator / Tests / Bias...



# Practice 4 (1h20 - 6 slides)

1. the hunter and the duck agin again again

1. Hunter and duck again and again
  about the coin? Is is biased? How to proceed.
    - what is the probability of obtaining such results if the $p$ (obtaining T)
    is 0? 1? 0.5? is 0.1?
    - compute $P(p\in[.4,.6])$
    - find a way to get a and b such as $P(p\in[a,b])=.95$
    - Let's introduce a second coin and a new set of data, are the two coins similar?




2. Same kind of exercise with a normal distribution.

3. Find a way to find the best parameter values?

- information update (20 min)


# Let's take a step back



# Project time


----

\begin{alertblock}{AlertBlock}
  Pass auf!
\end{alertblock}
